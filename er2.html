<html>
<head>
  <style>
  body {
    font-family: sans-serif;
    color: rgb(79,79,79);
    margin: 0 auto;
    max-width: 50%;
    line-height: 1.75;
    padding: 4em 1em;
    background-color: rgb(239, 245, 255);
  }
  .image {
    display: block;
    margin-left: auto;
    margin-right: auto;
  }
  @import url('https://fonts.googleapis.com/css?family=Muli');
  @import url('https://fonts.googleapis.com/css?family=Arsenal:');
  h1 {
    font-family: 'Aresenal', sans-serif;
    color: rgb(69,105,144);
  }
  h2 {
    font-family: 'Muli', sans-serif;
    color: rgb(17,75,95);
  }
  a {
    color: rgb(2,128,144);
  }
  a:hover {
    transition: all 0.3s;
    color: rgb(244,91,105);
  }
  </style>
</head>
<body>
  <h1> Ethical Reflection 2 </h1>
  <h2>The Danger of Corporations Collecting Our Data </h2>
  <img src="https://images.unsplash.com/photo-1506399558188-acca6f8cbf41?ixlib=rb-0.3.5&ixid=eyJhcHBfaWQiOjEyMDd9&s=44506d02c01a236c6ac088d527a56568&auto=format&fit=crop&w=500&q=60" class="image">
</img>
  <p><strong> By: Laura Ospina</strong></p>
<p>
  The posts you like, the ads you click, the information you are exposed to can define your entire personality. Even the most trivial pieces of data about you, such as late-night search history and a thumbs-up can begin to spin a tale and assign certain characteristics in order to encompass your humanity.
</p>
<p>
In this way, major companies have begun to collect and oftentimes, sell data about you and your behaviorisms. By setting up complex algorithms, they can discover, with particularly strong accuracy, gender, sexual orientation, parent separation, substance abuse, and other revealing information. Personal status updates or direct messages are not needed to divulge this information either, most of it is based on likes and search history.
</p>
<p>
The algorithms learn the characteristics of others who bought a service or good previously and target people who are similar. Advertisements would be the most obvious example, targeting certain demographics based on the information sold to them. But an ad floating on your screen isn’t thought of as potentially dangerous.
</p>
<p>
However, these Artificial Intelligence based algorithms can also discover political ideologies. Companies might target you with specific ads for a political platform, or in this age, fake news articles to attempt to change your beliefs and who you might vote for. As shown with the Cambridge Analytica scandal, this issue is as important as ever to ensure our right to democracy. We cannot allow the demand for a solid bottom line influence our elections.
</p>
<p>
But changing the given harvesting of data to preserve privacy, dignity, and democracy in our society isn’t the most simple of tasks. The intricate process of collecting and associating data with people is too hard to fully comprehend. No one knows exactly how computers and algorithms are completing the action. In addition to that, implementing legal ramifications and restrictions against algorithms is extremely difficult. AI is an forever changing area, new technology being developed everyday. This leaves legal terminology in documents, such as the General Data Protection Regulation of the UK, to be vague and open to interpretation and therefore, weak-willed.
</p>
<p>
Becoming aware of information collecting large corporations such as Google and Facebook are guilty of is a huge step towards knowing where our data is going. Although we hardly realize it, our lives are being silently manipulated into believing, buying, and following certain things. Just allowing algorithms to show us certain ads, in the big picture, is limiting our freedom of speech and thought.
</p>
<p>
AI and algorithms have a promising future and are an incredible tool for success and innovation. However, we must be aware of the spread of information and the terms in which computers are doing it. The personal details of millions of people that were never intended to be shared are currently being bought by companies looking to influence us and make a quick buck. Instead of focusing on a societal fear of computers and the unknown, we must look critically at those in power who control everything we know.
</p>
  <p><strong> Sources: </strong></p>

    <p>
      <a href="https://www.ted.com/talks/zeynep_tufekci_we_re_building_a_dystopia_just_to_make_people_click_on_ads">
      We're Building a Dystopia Just to Make People Click on Ads by Zeynep Tufekci</a>
    </p>
    <p>
      <a href="https://www.youtube.com/watch?v=KW0eUrUiyxo">How Ads Work on YouTube by
        CGP Grey </a>
    </p>
    <p>
      <a href="https://talkingtech.cliffordchance.com/en/cybersecurity/me--myself-and-ai--when-ai-meets-personal-data-.html">
        Me, Myself and AI by TalkingTech</a>
    </p>
    <p>
      <a href="https://www.theguardian.com/technology/2018/mar/17/facebook-cambridge-analytica-kogan-data-algorithm">
        How Cambridge Analytica turned Facebook ‘likes’ into a lucrative political tool by Carole
        Cadwalladr and Emma Graham-Harrison</a>
        </P
</body>
</html>
